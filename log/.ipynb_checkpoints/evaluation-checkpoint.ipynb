{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2B - Validation & Experimentation\n",
    "\n",
    "There are two parts to this week's lab.  The checkpoint for week 1 only involves Lab 2A, so return back to this file only after you have completed the checkpoint.\n",
    "\n",
    "## Learning Goals:\n",
    "\n",
    "The goal of this lab is to practice using good experimental design and methodology to train and test classifiers.  You will write some simple code to try doing this yourself, and you will also use the tools built into scikit-learn, numpy, and scipy-stats.\n",
    "\n",
    "As with any programming assignment, you'll also be practicing and improving your general CS skills, like problem decomposition, algorithmic thinking, implementation and testing, language syntax, etc.. Here are some of the specific things you should learn while completing this assignment:\n",
    "\n",
    "   * How to load and use python libraries to train and evaluate ML models in a more rigorous fashion (i.e. going beyond a single train/test split)\n",
    "   * The impact of a random seed value, and how to mitigate this impact\n",
    "   * How to measure performance in different ways (beyond just accuracy)\n",
    "\n",
    "   * How to use your understanding of a data set to figure out what performance measures are appropriate\n",
    "\n",
    "   * How to work independently to make choices about testing and applying machine learning methods\n",
    "\n",
    "\n",
    "Like the previous one, the assignment is presented in the form of an interactive Python notebook; it contains a mix of pre-made examples to help you understand how to do things, scaffolding with missing parts where you'll write your own code, and written short-answer questions. Your job is to fill in answers to the written questions (which may require you to modify scaffolding code and re-run it, or may require you to write your own code and run it), as well as write the indicated functions to complete the programming portion of the assignment. Look for the TODO: ... markers to help you spot places you'll need to complete things.\n",
    "\n",
    "Note that this notebook leaves more for you to fill in independently than the previous one, particularly in Part 5.  This is intentional; ultimately, you'll need to be able to work through this process with little or no guidance (e.g. for the final project).  This is your first chance to start practicing these skills, so ask questions if you're uncertain.\n",
    "\n",
    "This lab is intended to be done with a partner (i.e. teams of two); partners will be assigned based on your response to the partner preference survey.\n",
    "\n",
    "You'll have approximately two weeks to complete this full lab (both parts), so be sure to start early and plan properly to get it all done in a timely fashion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPSC 66 - Machine Learning\n",
    "# Lab 2B\n",
    "# Scaffolding by Prof. Ben Mitchell & Ameet Soni\n",
    "# Assignment completed by: Nathaniel, Patrick, Ethan\n",
    "# Resources used: \n",
    "#   <List any resources you used beyond the ones posted on Blackboard>\n",
    "#   <This can include books, websites, other students, etc.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math and numpy first\n",
    "import math\n",
    "import numpy as np\n",
    "# import scipy for stats package\n",
    "import scipy\n",
    "# import some data and classifiers to play with\n",
    "from sklearn import datasets\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# import some validation tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Multiple classifiers using SciKit Learn\n",
    "\n",
    "### Load some data\n",
    "\n",
    "SciKit Learn comes with a number of \"built-in\" datasets beyond the Iris dataset we've been using (see https://scikit-learn.org/stable/datasets/index.html for a full list).  For this assignment, we will load several datasets, and compare the performance of several classifiers on each of them.\n",
    "\n",
    "First we'll load the iris dataset again, since it's small and easy to play with.\n",
    "\n",
    "Go ahead and load it the same way we did in the previous lab, and split it into 60% train and 40% test just like we did there (refer to the Lab 1 scaffolding as a reference).\n",
    "\n",
    "**Be sure to use the argument `random_state=0` just like we did in the previous assignment.**  This is a \"seed\" for the random number generator; any particular seed value should always result in the same set of \"random\" numbers.  We'll use fixed seed values here because it will allow everyone to get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the iris dataset and split it into train and test sets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Nearest Neighbor classifier\n",
    "Create a nearest neighbor classifier using SKLearn just like we did in the previous lab; here, we will use it as a baseline for comparing our new classifiers.  Be sure to train it and then evaluate its performance on the testing data (again, you should be able to use code from the previous assignment with little or no modification to do this).  Use an n_neighbors value of 1.  This should give you the same accuracy as you got in the previous assignment.\n",
    "\n",
    "Once you've got it working, try changing the `random_state` value in the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to 1 and re-running your nearest-neighbor classifier.  Try it again with a value of 2.  Write down each of the accuracies below; the first one has been done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9166666666666666\n",
      "1: 0.9666666666666667\n",
      "2: 0.9666666666666667\n",
      "3: 0.9666666666666667\n",
      "4: 0.95\n",
      "5: 0.9666666666666667\n",
      "6: 0.95\n",
      "7: 0.95\n",
      "8: 0.95\n",
      "9: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# create, train, and test a nearest neighbor classifier\n",
    "\n",
    "classifier = neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.score(X_test, y_test)\n",
    "\n",
    "def KNN(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "\n",
    "    classifier = neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier.score(X_test, y_test)\n",
    "    \n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {KNN(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: accuracy of nearest neighbor for different random seed values**\n",
    "\n",
    "seed=0, accuracy = 0.9166666666666666\n",
    "\n",
    "seed=1, accuracy = 0.9666666666666667\n",
    "\n",
    "seed=2, accuracy = 0.9666666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Decision Tree\n",
    "\n",
    "Create a decision tree, using [`tree.DecisionTreeClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) as your classifier.  Train and test as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.95\n",
      "1: 0.9666666666666667\n",
      "2: 0.9333333333333333\n",
      "3: 0.95\n",
      "4: 0.9666666666666667\n",
      "5: 0.9666666666666667\n",
      "6: 0.95\n",
      "7: 0.9333333333333333\n",
      "8: 0.9333333333333333\n",
      "9: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# create, train, and test\n",
    "\n",
    "def decisionTree(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "    treeClassifier = tree.DecisionTreeClassifier()\n",
    "    treeClassifier = treeClassifier.fit(X_train, y_train)\n",
    "    return treeClassifier.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {decisionTree(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: accuracy of decision tree for different random seed values**\n",
    "\n",
    "seed=0, accuracy = 0.95\n",
    "\n",
    "seed=1, accuracy = 0.9666666666666667\n",
    "\n",
    "seed=2, accuracy = 0.9333333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a linear SVM\n",
    "Code to create a linear [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) is given; however, it is left to you to add lines to train the SVM on the training data and then evaluate its accuracy on the testing data.  This should work just like the training/testing process did using the nearest neighbor class, since SKLearn tries to provide the same API for all its classifiers (though many of them have algorithm specific options available).\n",
    "\n",
    "Test your classifier on different train/test splits using the same three random-seed values as previously, and report the accuracies you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9666666666666667\n",
      "1: 0.9833333333333333\n",
      "2: 0.9666666666666667\n",
      "3: 0.9666666666666667\n",
      "4: 0.9833333333333333\n",
      "5: 0.9833333333333333\n",
      "6: 0.9833333333333333\n",
      "7: 0.95\n",
      "8: 0.9333333333333333\n",
      "9: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def linSVM(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "    linearSvm = svm.SVC(kernel='linear')\n",
    "    linearSvm = linearSvm.fit(X_train, y_train)\n",
    "    return linearSvm.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {linSVM(i)}\")\n",
    "# train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: accuracy of linear SVM for different random seed values**\n",
    "\n",
    "seed=0, accuracy =0.966667\n",
    "\n",
    "seed=1, accuracy =0.9833333\n",
    "\n",
    "seed=2, accuracy = 0.966666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a polynomial-kernel SVM\n",
    "Create another SVM, only this time use the argument `kernel='poly'` to make an SVM using a polynomial kernel.  Train and test it with different seed values as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9\n",
      "1: 0.9833333333333333\n",
      "2: 0.9666666666666667\n",
      "3: 0.95\n",
      "4: 0.9833333333333333\n",
      "5: 0.9833333333333333\n",
      "6: 0.9833333333333333\n",
      "7: 0.95\n",
      "8: 0.95\n",
      "9: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# create, train, and test\n",
    "def polSVM(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "    polySvm = svm.SVC(kernel='poly')\n",
    "    polySvm = polySvm.fit(X_train, y_train)\n",
    "    return polySvm.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {polSVM(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4: accuracy of polynomial SVM for different random seed values**\n",
    "\n",
    "seed=0, accuracy = 0.9\n",
    "\n",
    "seed=1, accuracy = 0.9833333\n",
    "\n",
    "seed=2, accuracy = 0.9666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a rbf-kernel SVM\n",
    "\n",
    "Create another svm, this time using `'rbf'` for the kernel type.  Train and test as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9333333333333333\n",
      "1: 0.9833333333333333\n",
      "2: 0.9333333333333333\n",
      "3: 0.95\n",
      "4: 0.9833333333333333\n",
      "5: 0.9833333333333333\n",
      "6: 0.9333333333333333\n",
      "7: 0.9333333333333333\n",
      "8: 0.95\n",
      "9: 1.0\n"
     ]
    }
   ],
   "source": [
    "# create, train, and test\n",
    "def rbfSVM(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "    rbfSvm = svm.SVC(kernel='rbf')\n",
    "    rbfSvm = rbfSvm.fit(X_train, y_train)\n",
    "    return rbfSvm.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {rbfSVM(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5: accuracy of rbf SVM for different random seed values**\n",
    "\n",
    "seed=0, accuracy = 0.9333333333333333\n",
    "\n",
    "seed=1, accuracy = 0.9833333333333333\n",
    "\n",
    "seed=2, accuracy = 0.9333333333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression classifier\n",
    "Create a logistic regression classifier using the SGDClassifier (see lab 2A for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.85\n",
      "1: 0.9333333333333333\n",
      "2: 0.8333333333333334\n",
      "3: 0.7166666666666667\n",
      "4: 0.8\n",
      "5: 0.8833333333333333\n",
      "6: 0.95\n",
      "7: 0.9\n",
      "8: 0.8666666666666667\n",
      "9: 0.95\n"
     ]
    }
   ],
   "source": [
    "# create, train, and test\n",
    "def logistic(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "    sgd = SGDClassifier(loss='log', max_iter=100,shuffle=False, tol=None, penalty='none', learning_rate='constant', eta0 = 0.1)\n",
    "    sgd.fit(X_train,y_train) #\n",
    "    return sgd.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {logistic(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6: accuracy of Logistir Regression for different random seed values**\n",
    "\n",
    "seed=0, accuracy = 0.85\n",
    "\n",
    "seed=1, accuracy = 0.9333333333333333\n",
    "\n",
    "seed=2, accuracy = 0.8333333333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Repeated hold-out validation and Computing Statistics\n",
    "We've done 'hold-out' validation using the `train_test_split` method, but we've used a fixed seed value.  In the previous part, we manually changed the seed for the random-number generator to get different train/test splits so we could see how the performance of our classifiers changed.  This time, let's write a loop to do the same thing for us.  Copy your code from the previous section to split the data 60/40 and then train and test a SVM classifier with an RBF kernel, and put it inside a `for`-loop that runs 10 times.  Each time, seed the `train_test_split` function with the current loop iteration counter (i.e. the first time through, `train_test_split` should be 0, the second time through it should be 1, etc.).  The result should be 10 accuracy scores, which should be stable (i.e. if you re-run the cell, you get the same 10 numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9333333333333333\n",
      "1: 0.9833333333333333\n",
      "2: 0.9333333333333333\n",
      "3: 0.95\n",
      "4: 0.9833333333333333\n",
      "5: 0.9833333333333333\n",
      "6: 0.9333333333333333\n",
      "7: 0.9333333333333333\n",
      "8: 0.95\n",
      "9: 1.0\n"
     ]
    }
   ],
   "source": [
    "# todo\n",
    "def rbf2SVM(state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=state)\n",
    "    rbfSvm = svm.SVC(kernel='rbf')\n",
    "    rbfSvm = rbfSvm.fit(X_train, y_train)\n",
    "    return rbfSvm.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {rbf2SVM(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed\n",
    "\n",
    "Now try making a copy of the loop, but leave off the `random_state` argument entirely.  This version of the loop should give you output that is generally similar to the previous one, but each time you re-run it, you should get different scores.  This is because the 'default' for the `train_test_split` function is to not use a static seed value, so every time you run it you'll get a different result.  Read more [here](https://scikit-learn.org/stable/glossary.html#term-random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9666666666666667\n",
      "1: 0.9666666666666667\n",
      "2: 0.9666666666666667\n",
      "3: 0.95\n",
      "4: 0.9333333333333333\n",
      "5: 0.9666666666666667\n",
      "6: 0.95\n",
      "7: 0.9333333333333333\n",
      "8: 0.95\n",
      "9: 0.9666666666666667\n",
      "\n",
      "\n",
      "0: 0.8833333333333333\n",
      "1: 0.95\n",
      "2: 0.9333333333333333\n",
      "3: 0.9833333333333333\n",
      "4: 0.9666666666666667\n",
      "5: 0.9166666666666666\n",
      "6: 0.9666666666666667\n",
      "7: 0.9166666666666666\n",
      "8: 0.9666666666666667\n",
      "9: 0.95\n"
     ]
    }
   ],
   "source": [
    "def rbf3SVM():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4)\n",
    "    rbfSvm = svm.SVC(kernel='rbf')\n",
    "    rbfSvm = rbfSvm.fit(X_train, y_train)\n",
    "    return rbfSvm.score(X_test, y_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {rbf3SVM()}\")\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "for i in range(10):\n",
    "    print(f\"{i}: {rbf3SVM()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Statistics\n",
    "\n",
    "Make copy of the previous cell (i.e. the loop without fixed seeds), but this time instead of printing the individual scores, store them in a list.  The easiest way to do this is to start with an empty list (e.g. `myList = []`), and then add numbers using the `.append()` method.  After the loop is done, print out your list to be sure it looks the way you expect (you should be able to do this with a single print, e.g. `print(myList)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.95, 0.9333333333333333, 0.9333333333333333, 0.95, 1.0, 1.0, 0.95, 0.9666666666666667, 0.95]\n"
     ]
    }
   ],
   "source": [
    "def rbf4SVM():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4)\n",
    "    rbfSvm = svm.SVC(kernel='rbf')\n",
    "    rbfSvm = rbfSvm.fit(X_train, y_train)\n",
    "    return rbfSvm.score(X_test, y_test)\n",
    "\n",
    "myList= []\n",
    "for i in range(10):\n",
    "    myList.append(rbf4SVM())\n",
    "\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "Compute the mean (average) of the list of numbers you made in the previous step; this is the average accuracy over your 10 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance & Standard Deviation\n",
    "Now compute the variance and standard deviation of your list of accuracies.  The standard deviation is the square root of the variance, and the variance is basically just the average squared differences from the mean.  \n",
    "\n",
    "This will be a bit like the loop you wrote to calculate Euclidean distance, only now you're subtracting the mean rather than a coordinate of another point, and you're going to be dividing by the number of items in the list minus one before you take the square root.  \n",
    "\n",
    "\n",
    "Note that the symbol for standard deviation is $\\sigma$; there's no standard symbol for variance, it's just $\\sigma^2$.  Here's the equations, where $n$ is the number of items in the list, $x_i$ is the $i$-th element of the list, and $\\mu$ is the mean:\n",
    "\n",
    "$$ \\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\mu)^2 $$\n",
    "\n",
    "$$ \\sigma = \\sqrt{\\sigma^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our var: 0.0005679012345679016    our std: 0.023830678432808027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=10, minmax=(0.9333333333333333, 1.0), mean=0.96, variance=0.0005679012345679014, skewness=0.7500308204401336, kurtosis=-0.6361058601134184)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def variance(l):\n",
    "    mu = np.mean(l)\n",
    "    s = 0\n",
    "    for i in range(len(l)):\n",
    "        s += (l[i]-mu)**2\n",
    "    return s/(len(l)-1)\n",
    "        \n",
    "def standardDev(l):\n",
    "    return np.sqrt(variance(l))\n",
    "\n",
    "print(f\"our var: {variance(myList)}    our std: {standardDev(myList)}\")\n",
    "scipy.stats.describe(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats using scipy\n",
    "To check and see if you've calculated your statistics correctly, you can use the `scipy.stats` library.  In particular, if you call the method `scipy.stats.describe()` and give it a list of numbers as an argument, it will report a variety of statistics, including mean and variance.  Make sure that these values match the ones you've calculated above.  See https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.describe.html#scipy.stats.describe for documentation.\n",
    "\n",
    "In the future, it's fine to use the stats library to do this kind of thing for you, but it's a lot easier to understand the numbers coming out of the stats library once you've written code to calculate those numbers yourself.  You can also use this as a reference implementation, to check that your own code produces the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=10, minmax=(0.9333333333333333, 1.0), mean=0.96, variance=0.0005679012345679014, skewness=0.7500308204401336, kurtosis=-0.6361058601134184)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.describe(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: K-Fold Cross-validation\n",
    "\n",
    "Now we'll use scikit-learn to do some more complicated types of validation.  Repeatedly re-spliting the data is okay, but it's not ideal from a statistical reliability standpoint (as we discussed in class).  Therefore, a better practice is to use k-fold cross-validation, as shown in this example.  Note the parameter `cv=5`; this is how many 'folds' to use, and will also be how many scores you get out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.96666667, 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the accuracies\n",
    "\n",
    "Since `cross_val_score` returns a numpy array, we can use numpy methods to get the mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9666666666666666 , stdDev: 0.02108185106778919\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy:', scores.mean(), ', stdDev:', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated K-fold (aka N-by-K fold)\n",
    "If you try running the cross-validation cell multiple times, you'll notice you get the same values back every time.  That's because `cross_val_score` doesn't shuffle the data randomly every time you call it.  If we actually want to re-run cross-validation with a new set of point-to-fold assignmenst, we can use the function `RepeatedKFold`, to get a set of folds, and then hand it to `cros_val_score` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.86666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "       0.96666667, 0.93333333, 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 3)\n",
    "scores2 = cross_val_score(clf, iris.data, iris.target, cv = rkf)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.9       , 0.93333333, 1.        , 1.        ,\n",
       "       0.93333333, 1.        , 1.        , 1.        , 0.9       ,\n",
       "       0.96666667, 0.9       , 0.96666667, 1.        , 0.96666667])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 3)\n",
    "scores2 = cross_val_score(clf, iris.data, iris.target, cv = rkf)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9644444444444444 , stdDev: 0.039377878103709664\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy:', scores2.mean(), ', stdDev:', scores2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try using N-by-K to compare some classifiers\n",
    "\n",
    "Last week, we tried to compare some classifiers by hand; this week, lets use cross-validation and statistics.\n",
    "\n",
    "First, we'll run 5-fold cross-validation with 4 repeats to train and test a Nearest Neighbor classifier and a Linear-kernel SVM.  Each should give you an array of 20 accuracy values.  Print the mean and standard deviation for each classifier, then print the difference between the means.  Finally, use `scipy.stats.mannwhitneyu()` to check the $p$ value and see whether the difference is statistically significant (just hand it the two score arrays as inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds:  10  Repeats:  2\n",
      "Nearest Neighbor: mean = 0.9566666666666667 , stdDev = 0.043588989435406726\n",
      "Linear SVM: mean = 0.9833333333333334 , stdDev = 0.02886751345948128\n",
      "Difference between means: 0.026666666666666727\n",
      "MannwhitneyuResult(statistic=135.0, pvalue=0.04274370144542344)\n",
      "\n",
      "\n",
      "Folds:  10  Repeats:  10\n",
      "Nearest Neighbor: mean = 0.9600000000000002 , stdDev = 0.04714045207910316\n",
      "Linear SVM: mean = 0.9800000000000001 , stdDev = 0.033333333333333326\n",
      "Difference between means: 0.019999999999999907\n",
      "MannwhitneyuResult(statistic=3893.0, pvalue=0.0015569006425985915)\n",
      "\n",
      "\n",
      "Folds:  10  Repeats:  100\n",
      "Nearest Neighbor: mean = 0.9587333333333333 , stdDev = 0.04750854893829343\n",
      "Linear SVM: mean = 0.9787333333333333 , stdDev = 0.03585396305384756\n",
      "Difference between means: 0.020000000000000018\n",
      "MannwhitneyuResult(statistic=386629.0, pvalue=1.928020798382081e-24)\n",
      "\n",
      "\n",
      "Folds:  100  Repeats:  10\n",
      "Nearest Neighbor: mean = 0.9605 , stdDev = 0.16938048884095241\n",
      "Linear SVM: mean = 0.9785 , stdDev = 0.1256493135675639\n",
      "Difference between means: 0.018000000000000016\n",
      "MannwhitneyuResult(statistic=486983.0, pvalue=0.0050060663355130505)\n",
      "\n",
      "\n",
      "Folds:  100  Repeats:  100\n",
      "Nearest Neighbor: mean = 0.96065 , stdDev = 0.16681300159160256\n",
      "Linear SVM: mean = 0.9806 , stdDev = 0.11778641687393328\n",
      "Difference between means: 0.019950000000000023\n",
      "MannwhitneyuResult(statistic=48518172.5, pvalue=2.9802741436250315e-24)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def rkfFunc(folds, repeats):    \n",
    "    rkf = RepeatedKFold(n_splits = folds, n_repeats = repeats)\n",
    "\n",
    "    nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "    svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "    nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "    svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "    print(\"Folds: \", folds, \" Repeats: \", repeats)\n",
    "    print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "    print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "    print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "    print(scipy.stats.mannwhitneyu(nnScores, svmScores))\n",
    "\n",
    "    print('\\n')\n",
    "    #scipy.stats.mannwhitneyu(nnScores, svmScores)\n",
    "\n",
    "for f, r in [(10, 2), (10, 10), (10, 100), (100, 10), (100, 100)]:\n",
    "        rkfFunc(f, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different values of K and N\n",
    "\n",
    "Repeat the above experiment using the values of K and N below, and report the mean, stdDev, differece between the means, and p-value for each.  The first row has been completed for you (note that your numbers may be slightly different, since this is a stochastic process).  Also notice how long these take to finish (though you don't need to write that down).  Once the table is complete, look at it and try to see what patterns you can spot.\n",
    "\n",
    "Remember that we're working with a pretty trivial toy problem here; the point is the process and methodology, not the exact magnitude of the scores.\n",
    "\n",
    "_NOTE: please limit values to a reasonable number of sig figs_\n",
    "\n",
    "***\n",
    "\n",
    "Folds | Repeats  |   NN-mean  |  NN-stdev  | SVM-mean  |  SVM-stdDev  |  difference   |  p-value\n",
    "------|----------|------------|------------|-----------|--------------|---------------|--------------\n",
    "5     |      4   |    0.957   |   0.035    |  0.977    |   0.032      |     0.033     |   0.032\n",
    "2     |      10  |    0.951   |   0.0198   |  0.967    |   0.012      |     0.015     |   0.008\n",
    "10    |      2   |    0.956   |   0.0528   |  0.980    |   0.039      |     0.023     |   0.109\n",
    "10    |      10  |    0.957   |   0.046    |  0.980    |   0.0394     |     0.0213    |   0.00070136\n",
    "10    |     100  |    0.959   |   0.047    |  0.978    |   0.03799    |     0.01893   |   1.65e-23\n",
    "100   |      10  |    0.957   |   0.181    |  0.975    |   0.149      |     0.0189    |   0.00216\n",
    "100   |     100  |    0.960   |   0.1697   |  0.979    |   0.125      |     0.0193    |   1.8468e-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Alternative Metrics\n",
    "\n",
    "Up until now, we've just worked with overall accuracy as our only way of \"scoring\" the performance of a classifier.  Now, we will try out some alternative tools for evaluating classifier performance.  In addition to the `.scores()` method, scikit-learn classifiers have a `.predict()` method which takes in a set of examples as an argument, and returns an array with the predicted labels for those examples.  Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels:  [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 1 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2]\n",
      "true labels:  [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "train, test, trainLabels, testLabels = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train, trainLabels)\n",
    "predictions = clf.predict(test)\n",
    "print('predicted labels: ', predictions)\n",
    "print('true labels: ', testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "By comparing the predicted labels to the 'true' labels, we could easily compute accuracy like we've done in the past.  This time, however, we want to drill down and get more details, so we're going to build a confusion matrix.\n",
    "\n",
    "A confusion matrix works by making a 2D array (i.e. a matrix), with the rows corresponding to 'true' class labels and the columns corresponding to 'predicted' class labels.  You just need to loop over the pairs of corresponding true/predicted labels, and add to the count in the corresponding cell of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  1 20]]\n"
     ]
    }
   ],
   "source": [
    "# todo\n",
    "confusionMatrix = [[0]*3, [0]*3, [0]*3]\n",
    "for i in range(len(predictions)):\n",
    "    confusionMatrix[predictions[i]][testLabels[i]] += 1\n",
    "print(np.array(confusionMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix using scikit-learn\n",
    "\n",
    "We can also ask scikit-learn to generate a confusion matrix for us, as the following example shows.  Your own confusion matrix should look just like the one produced by the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  1 20]]\n"
     ]
    }
   ],
   "source": [
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fancy Graphics\n",
    "\n",
    "It's also possible to use Python's plotting tools to make fancy graphical versions of a confusion matrix; the following example is adapted from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html.  _NOTE:_ it's fine if you don't understand what this function is doing; we haven't really covered making plots yet.  For now, it's okay if this is just magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confMat, classes=iris.target_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confMat, classes=iris.target_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Different data sets\n",
    "\n",
    "Up until now, we've mostly just considered a single data set at a time; that was fine when we were focused mainly on understanding how the classifiers worked, but we also need to get a feel for how much difference there is between different data sets.  Here, we will load up a few different data sets provided by SciKit learn.\n",
    "\n",
    "Note that we use the argument `as_frame=True` here to ask SciKit to give us the data in the form of a Pandas dataframe object (as opposed to the \"default\" form, which we saw when we loaded the Iris data set above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits type: <class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "# load the Wisconsin Breast Cancer data set as a Pandas dataframe\n",
    "cancer = datasets.load_breast_cancer(as_frame=True)\n",
    "X = cancer['data']\n",
    "X=(X-X.min())/(X.max()-X.min()) # normalize the data to make each column be in the range [0-1]\n",
    "cancer['data'] = X\n",
    "\n",
    "# load a handwritten-digit-classification data set as a Pandas dataframe\n",
    "digits = datasets.load_digits(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use what you've learned\n",
    "\n",
    "Use what you've learned from the earlier parts of this assignment to compare the performance of each of the classifiers we've studied (KNN, SVM, Decision Tree) on each of these datasets.  \n",
    "\n",
    "Your response should be a mix of code cells and markdown cells; make sure you include markdown cells *describing* the dataset and *explaning* what choices you made for that data set and why.\n",
    "\n",
    "\n",
    "Be sure to compare the different performance measures we've talked about, and note which ones are likely most important for the dataset in question.  Then, describe what you can conclude about the problem by comparing them (e.g. are some types of examples easier or harder than others? are some classes more similar or easier to confuse? etc.)\n",
    "\n",
    "At a minimum, for each problem you should describe  what type of model you chose, why(/how) you chose it, and how you chose to evaluate that model (both in terms of choosing a performance measure and in terms of how you ensure your estimate of that measure is reliable).\n",
    "\n",
    "For the first dataset, some cells with comments have been provided; for the second dataset, you should create a similar structure yourself.  Feel free to add in extra cells here, or change things around if appropriate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5a: Breast Cancer\n",
    "\n",
    "Here you will examine the Wisconsin Breast Cancer data set.\n",
    "\n",
    "## Data set description\n",
    "\n",
    "Use the code box below to examines the data set and then describe the data set in the Markdown box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds:  10  Repeats:  2\n",
      "Nearest Neighbor: mean = 0.9577224310776942 , stdDev = 0.028303100650274297\n",
      "Linear SVM: mean = 0.9771773182957393 , stdDev = 0.02155453927249671\n",
      "Decision Tree: mean = 0.9358395989974937 , stdDev = 0.025036523028969436\n",
      "Difference between SVM and K-Nearest Neighbor means: 0.019454887218045114\n",
      "Difference between SVM and Decision Tree means: 0.04133771929824559\n",
      "Difference between K-Nearest Neighbor and Decision Tree means: 0.021882832080200476\n",
      "MannwhitneyuResult(statistic=122.5, pvalue=0.03349685074963678)\n",
      "MannwhitneyuResult(statistic=45.0, pvalue=2.3417970918469327e-05)\n",
      "MannwhitneyuResult(statistic=288.0, pvalue=0.016106683863466812)\n",
      "\n",
      "\n",
      "Folds:  10  Repeats:  10\n",
      "Nearest Neighbor: mean = 0.9539411027568923 , stdDev = 0.02437282875463225\n",
      "Linear SVM: mean = 0.9761152882205514 , stdDev = 0.021446889750453113\n",
      "Decision Tree: mean = 0.9248026315789473 , stdDev = 0.03507326767261488\n",
      "Difference between SVM and K-Nearest Neighbor means: 0.022174185463659124\n",
      "Difference between SVM and Decision Tree means: 0.051312656641604115\n",
      "Difference between K-Nearest Neighbor and Decision Tree means: 0.02913847117794499\n",
      "MannwhitneyuResult(statistic=2426.0, pvalue=1.482093230224425e-10)\n",
      "MannwhitneyuResult(statistic=1007.0, pvalue=7.165783385495748e-23)\n",
      "MannwhitneyuResult(statistic=7410.5, pvalue=2.6786300033356566e-09)\n",
      "\n",
      "\n",
      "Folds:  10  Repeats:  100\n",
      "Nearest Neighbor: mean = 0.953233709273183 , stdDev = 0.02598806615833957\n",
      "Linear SVM: mean = 0.9767882205513785 , stdDev = 0.018658106200231096\n",
      "Decision Tree: mean = 0.9253176691729323 , stdDev = 0.03356156525595736\n",
      "Difference between SVM and K-Nearest Neighbor means: 0.023554511278195522\n",
      "Difference between SVM and Decision Tree means: 0.05147055137844614\n",
      "Difference between K-Nearest Neighbor and Decision Tree means: 0.027916040100250616\n",
      "MannwhitneyuResult(statistic=237553.5, pvalue=4.184089205560606e-95)\n",
      "MannwhitneyuResult(statistic=85564.5, pvalue=3.899944429260484e-230)\n",
      "MannwhitneyuResult(statistic=741986.5, pvalue=5.5182313806299995e-80)\n",
      "\n",
      "\n",
      "Folds:  100  Repeats:  10\n",
      "Nearest Neighbor: mean = 0.9525333333333335 , stdDev = 0.08829385281232462\n",
      "Linear SVM: mean = 0.9768333333333333 , stdDev = 0.06643271449787036\n",
      "Decision Tree: mean = 0.9286666666666668 , stdDev = 0.11002221997800665\n",
      "Difference between SVM and K-Nearest Neighbor means: 0.024299999999999877\n",
      "Difference between SVM and Decision Tree means: 0.04816666666666658\n",
      "Difference between K-Nearest Neighbor and Decision Tree means: 0.023866666666666703\n",
      "MannwhitneyuResult(statistic=438157.5, pvalue=8.875666946974153e-13)\n",
      "MannwhitneyuResult(statistic=390034.5, pvalue=2.9836915670768227e-31)\n",
      "MannwhitneyuResult(statistic=549955.5, pvalue=1.218697174070006e-06)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def rkfFuncCancer(folds, repeats):    \n",
    "    rkf = RepeatedKFold(n_splits = folds, n_repeats = repeats)\n",
    "    \n",
    "    nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "    svmLinear = svm.SVC(kernel='linear')\n",
    "    treeClassifier = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    nnScores = cross_val_score(nn, cancer.data, cancer.target, cv = rkf) #we are here (can)\n",
    "    svmScores = cross_val_score(svmLinear, cancer.data, cancer.target, cv = rkf)\n",
    "    treeScores = cross_val_score(treeClassifier, cancer.data, cancer.target, cv = rkf)\n",
    "    \n",
    "    print(\"Folds: \", folds, \" Repeats: \", repeats)\n",
    "    print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "    print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "    print('Decision Tree: mean =', treeScores.mean(), ', stdDev =', treeScores.std())\n",
    "    print('Difference between SVM and K-Nearest Neighbor means:', svmScores.mean() - nnScores.mean())\n",
    "    print('Difference between SVM and Decision Tree means:', svmScores.mean() - treeScores.mean())\n",
    "    print('Difference between K-Nearest Neighbor and Decision Tree means:', nnScores.mean() - treeScores.mean())\n",
    "    print(scipy.stats.mannwhitneyu(nnScores, svmScores))\n",
    "    print(scipy.stats.mannwhitneyu(treeScores, svmScores))\n",
    "    print(scipy.stats.mannwhitneyu(nnScores, treeScores))\n",
    "\n",
    "    print('\\n')\n",
    "    #scipy.stats.mannwhitneyu(nnScores, svmScores)\n",
    "\n",
    "for f, r in [(10, 2), (10, 10), (10, 100), (100, 10)]:\n",
    "        rkfFuncCancer(f, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "***Todo: Describe the breast cancer dataset here*** (hint: consider the questions that were asked about datasets in the previous lab)\n",
    "\n",
    "This dataset is a set of info data about the cells seen in scans of women with and without breast cancer. This is meant to be used for training a classifier that could classify breast cancer in patients based on scans and measirements of their cells. The risks of this data set are fairly high as a false negative would be devastating as a patient would be unable to get treatment that they would need if a doctor was not also using traditional scans. If the doctor is looking at traditional scans, false positives can be terrible as they would likely put patients through trauma and invasive treatment that they would not need, and if it is being used to detect cancers that have not yet grown visible in other scans, this positive would not be verifiable elsewhere. Since failing to detect cancer might cause the patient's death, false negatives would be worse than false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Weighted models can be used to gauge what is known as _feature importance_ - the relative influence a feature has on the prediction task.  We can use the weights in logistic regression as a proxy for how relavent the feature is.  Similarly, for decision trees, the height a feature is placed in the tree tells us something about how important that feature is. Use the code box below to calculate feature importance and then answer the analysis questions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients and intercept for SKlearn SGDClassifier: \n",
      "mean radius has a weight of -0.6467905249151195 \n",
      "\n",
      "mean texture has a weight of -2.442467089799789 \n",
      "\n",
      "mean perimeter has a weight of -0.8765276767090724 \n",
      "\n",
      "mean area has a weight of -2.0107749489313296 \n",
      "\n",
      "mean smoothness has a weight of 0.16804522801822608 \n",
      "\n",
      "mean compactness has a weight of 0.42048812954997095 \n",
      "\n",
      "mean concavity has a weight of -4.5737900771265 \n",
      "\n",
      "mean concave points has a weight of -5.9896151963528865 \n",
      "\n",
      "mean symmetry has a weight of -1.2696938961312956 \n",
      "\n",
      "mean fractal dimension has a weight of 3.0560460536281697 \n",
      "\n",
      "radius error has a weight of -4.255202844473158 \n",
      "\n",
      "texture error has a weight of 0.10409341726948466 \n",
      "\n",
      "perimeter error has a weight of -3.0623844172135013 \n",
      "\n",
      "area error has a weight of -2.889033177789699 \n",
      "\n",
      "smoothness error has a weight of 1.1372572103530045 \n",
      "\n",
      "compactness error has a weight of 3.5286306933175844 \n",
      "\n",
      "concavity error has a weight of 1.1489873311206795 \n",
      "\n",
      "concave points error has a weight of 1.2440840234092336 \n",
      "\n",
      "symmetry error has a weight of -0.5291094817849151 \n",
      "\n",
      "fractal dimension error has a weight of 2.459061815597162 \n",
      "\n",
      "worst radius has a weight of -3.9734543501786685 \n",
      "\n",
      "worst texture has a weight of -4.5985948428634495 \n",
      "\n",
      "worst perimeter has a weight of -3.5022077044507607 \n",
      "\n",
      "worst area has a weight of -3.9726138830986746 \n",
      "\n",
      "worst smoothness has a weight of -2.482918889783381 \n",
      "\n",
      "worst compactness has a weight of -0.16121337663409932 \n",
      "\n",
      "worst concavity has a weight of -3.058379635259948 \n",
      "\n",
      "worst concave points has a weight of -5.980130130997101 \n",
      "\n",
      "worst symmetry has a weight of -3.1831122458704693 \n",
      "\n",
      "worst fractal dimension has a weight of -1.0085539322287518 \n",
      "\n",
      "Coefficients and intercept for linear svm: \n",
      "mean radius has a weight of -0.9850591921424848 \n",
      "\n",
      "mean texture has a weight of -1.01098955614795 \n",
      "\n",
      "mean perimeter has a weight of -0.9744493732981279 \n",
      "\n",
      "mean area has a weight of -0.9426191768372139 \n",
      "\n",
      "mean smoothness has a weight of -0.37355873570397025 \n",
      "\n",
      "mean compactness has a weight of 0.1338729655467794 \n",
      "\n",
      "mean concavity has a weight of -1.1249041589917426 \n",
      "\n",
      "mean concave points has a weight of -1.497820392269943 \n",
      "\n",
      "mean symmetry has a weight of -0.7506723077638522 \n",
      "\n",
      "mean fractal dimension has a weight of 0.5055332140251877 \n",
      "\n",
      "radius error has a weight of -0.9777610939108227 \n",
      "\n",
      "texture error has a weight of 0.10033342144283264 \n",
      "\n",
      "perimeter error has a weight of -0.7075032334138041 \n",
      "\n",
      "area error has a weight of -0.6865208579621405 \n",
      "\n",
      "smoothness error has a weight of -0.01101288729922012 \n",
      "\n",
      "compactness error has a weight of 0.5240438976089156 \n",
      "\n",
      "concavity error has a weight of 0.1844605902869946 \n",
      "\n",
      "concave points error has a weight of 0.47794037503578024 \n",
      "\n",
      "symmetry error has a weight of -0.42439114177938253 \n",
      "\n",
      "fractal dimension error has a weight of 0.43595720363230595 \n",
      "\n",
      "worst radius has a weight of -1.5876595801205409 \n",
      "\n",
      "worst texture has a weight of -1.5112701758556535 \n",
      "\n",
      "worst perimeter has a weight of -1.4506933440338163 \n",
      "\n",
      "worst area has a weight of -1.2351081958445458 \n",
      "\n",
      "worst smoothness has a weight of -1.1449996931159563 \n",
      "\n",
      "worst compactness has a weight of -0.26977984361251295 \n",
      "\n",
      "worst concavity has a weight of -1.0264904252522016 \n",
      "\n",
      "worst concave points has a weight of -1.5549816077782115 \n",
      "\n",
      "worst symmetry has a weight of -1.2093658018597009 \n",
      "\n",
      "worst fractal dimension has a weight of -0.5174294746378171 \n",
      "\n",
      "weights of tree:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABEOUlEQVR4nO29fVhU553//zriA0QYeZhRtCJEUAFDQbQaozUaJdvkl2SbrI2VdKNNsrVu8uvP66ptUhvtt+nuJpvUysb0wRaUYIOGbzZW1AWjFENGjXVJmMQIoyDDmBCIIgFEBwTu3x9kTgcBYZinM3C/rutcF5y555z3+Xxm7vncn/tJEUIgkUgkEu8wytcCJBKJZCQhK12JRCLxIrLSlUgkEi8iK12JRCLxIrLSlUgkEi8iK12JRCLxIrLSlUgkEi8iK12JRCLxIqN9LUAiGYigoKA6m802ydc6bkVgYGD99evXI32tQ6J9FDkjTaJ1FEURWv+cKoqCEELxtQ6J9pHpBYlEIvEistKVSCQSLyJzuhK/Zc+ePYSGhhIeHs7hw4d5+umnMRqNnDt3jkmTJrFkyRJiYmLU8l1dXYwa1TvO+MMf/sCoUaP4wQ9+QGNjI++++y7Xr1/nO9/5DmvXriUrK4uCggIaGxv5/ve/78UnlAxHZKUr8VsefPBB1qxZw3//939TXl5OREQEY8eO5Tvf+Q4Wi0Utl5+fD0B0dDQTJkygoqICgLS0NAICArjtttvUsmFhYcyaNYuqqioKCgpYtGgR48aNY/LkyXzxxRdefT7J8ESmFyR+y969e9myZQtFRUXquZqamh7RLcDs2bNRFIWuri66urro6Oigo6NDfb21tZXr169TWVmJ1WolIyODqVOncvXqVSorK6mpqaGurg5Fkf1kEteRka7Eb3nqqafUv3NzcwH44Q9/CEBVVRV33HEHAEFBQSxdupSQkBAApk+frr7PbDYzfvx4DAYDcXFxAHz55ZekpKTw6aefoigK0dHRREdHe+WZJMMfWelKhgXp6elkZWXR3t5OQkICAQEBvPLKKxgMBubNm0dMTAwhISEcP36clpYWIiMjSUlJobS0lPT0dLXSNhqNJCcnA7Bo0SJaW1t9+ViSYYisdCXDDnsaICEhoddrnZ2ddHR00NnZCUBqaip79uxBr9djMpm4fPkyDQ0NWK1WSkpKePjhh72qXTL8kZMjJJpnsJMjKioqKCwsZOXKlUydOtULyv6OnBwhGSyy0pVoHjkjTTKckKMXJCOC7Oxsp8oXFRXxyiuvAPDss89isVjIysri2LFj7hcnGVHInK7Eb9m+fTuJiYl0dXVRXFzM+vXr2bp1K8HBwURERJCWlkZeXh4RERFMmDCBoqIiTp48yYoVK9i/fz9r1qwhPj4ei8XSa+zujBkzMBqNmM1mpkyZAsDy5ct7jP+VSIaCjHQlfktSUhJGo5GmpiaioqKoqqoiJSWFuLg45syZQ3BwcI/yNpuNxMREwsLCSE5Oxmg0AvQ5dvfs2bOMGTMGi8VCW1sbVquVsrIyPvzwQ68+o2T4IXO6Es0z1JyuxWLBYrGwdOlS94u6CZnTlQwWWelKNI/sSJMMJ2R6QeLXONtBlpGRQXNzM5s3b8ZisfDhhx+yY8cOPv74Y7Zt28brr7+ulm1vb2ffvn1kZWXxySef8NJLL/U4Z7Vanb6/RCIrXYnfkJ2dzcGDB6mpqWHTpk2888476nmLxUJBQQE/+9nP2LFjBwDNzc0UFhZSWFjIpUuXAAgNDUWn07F8+XIA5syZw+jRo5kyZQq33347H3/8sXq/sWPHsnDhQsaOHcvs2bOJjIzscW7atGletoBkOCArXYnfEB0dTUVFBXV1daSmpnLmzBkAxo0bR1FREUIIdDodM2bMAEAIoXaQ3ZyesHeKvfnmmzQ2NiKEICAggKSkJHVVsvb2djZt2kRsbCwXL17EZDJRX1+vnpNIhoLM6Uo0jztzugcPHmTJkiXodDqXr2W1WrFarSxevFjmdCWDRo7TlWgaRVG+ERgY2K4oylhfa7kVgYGBrYqihAshrvhai0TbyPSCRJMoijJTUZQ84C82m+1HwFghhKLFA/iazWZ7AzArivKsoii33frpJCMZWelKNIWiKJMVRfkDcAIoA2YKIXYIIW74Vln/CCFqhRDrgMXAPOCcoij/oiiKbElKeiFzuhKfonSvw6gDFOCnwDpgF/CiEKLBl9qGiqIo84GXgCnAXgAhxP/xpSaJdpC/xBJf8yPgKWAScBCYI4Sw+laSawgh/qYoynLg/wH+CExWFKVWCPFHH0uTaABZ6Up8hqIo04FtwDXg/wghfu1jSW5DCCEURSkGXgdSgfE+liTRCDK9IPEZiqIEAN8BLgJnhBBNPpYkkXgcWemOAIKCgupsNtskX+uwExgYWH/9+vVIX+vwFVrzhyMj3TfeQFa6IwCtLRgz0icSaM0fjox033gDOWRMIpFIvIjsSBtB7Nmzh9DQUMLDwzl8+DBPPPEEpaWlKIqCXq+nuLiYZ555hl27drFhw4Ye7xVCqLvs2jEajXz22WdERUVx1113cfz4cd5//33WrVvHn/70J5YtW8axY8e44447WLFihRef1L/wtF9OnTrF6dOneeaZZygoKKC+vp4bN27Q0dHBI488wqRJmsx0DFtkpDuCePDBB8nMzGTBggVMmzaNqVOnotfrMRgMzJgxg2vXrhEcHExoaCgANTU15OXlkZ+fT1tbG0ePHqWwsBCz2QzAhQsXWLVqFZWVlQAsWrSIgIAAysrKUBSF69evExUVRWNjo7rluaQ3nvbLggULCA4Opr29nba2NqC7sr58+TKBgYE+eeaRjKx0RxB79+5ly5YtFBUVAWA2m8nLyyM8PJzy8nKCg4Ox2Wxq+cjISCIiIhBC9NjSpqurC4CYmBjy8vKYPn06JpOJjIwMgoODuf322xFCUFlZyaRJk6iqquL69es+eWZ/wNN+MZvNmEwmysvLge6Ferq6upg8eTKXL1/2/gOPcGRH2gigr46b3Nxc0tPTe5Vtbm6mpKSEBx54wJN6RnRnza060nzpl6+0jWjfeANZ6Y4ABtNbbjabmTVrFgC1tbWEhIQQEhLSZ7lTp05hMBi47777OHToEFeuXOHOO+9kx44dPPXUU2o+MjExkZSUlL70jOgv9mBHLwzVJx9++CF/+9vfuPfee9m5cydPPvkk7e3tGI1GUlNT+/SJg7YR7RtvIDvSRjBZWVm0t7eTkJCAxWJh586dGAwG5s2bR0xMDCEhIRw/fpyWlhYiIyNJSUmhtLSU9PR0cnNzAWhoaGD16tW89dZbREVFcenSJcaMGUNVVRXz58/38RP6H+7wyZw5c/jggw8IDQ1Vd8iIjY3lwIEDBAUF+fLxJMhKVwJq73dCQkKv1zo7O+no6FA7wlJTU9mzZw96vR6TyUR4eDh79+7l61//OkFBQZSXlxMYGMjMmTP5/PPPiYuL8+qzDBdc8UlFRYXaeVlWVkZjYyNXr15Fr9fT2Njo1eeQ9EamF0YA/TVnKyoqKCwsZOXKlUydOtWbekZ0E/ZW6QVf+cTOSPeNN5CV7ghgqDOgsrOzWbt27aDL5+fnY7VaSUlJUceJlpeXExsby9KlSx31jOgvtisz0pz1SVZWlmr/Z599lvXr11NYWMioUaP4wQ9+0Je2Ee0bbyDTCyOM7du3k5iYSFdXF8XFxaxfv56tW7cSHBxMREQEaWlp5OXlERERwYQJEygqKuLkyZOsWLGC/fv3s2bNGuLj47FYLFRUVACQlpZGQEAAy5cvJycnhwsXLvD444+Tk5PD8uXLsVgsvn1ojeNpn1gsFsxmM1OmTAHgttvkxha+RI7THWEkJSVhNBppamoiKiqKqqoqUlJSiIuLY86cOQQHB/cob7PZSExMJCwsjOTkZIxGI0CP8aF2Nm7cyPTp03uME7XvuivpH0/6xG5/i8VCW1sbVquV1tZWOW7ah8j0wgjAmeasxWLBYrH0SAd4QM+IbsI6m17whk/sjHTfeANZ6Y4AtLaq1Uj/YmvNH46MdN94A5leGOFkZ2c7VT4jI4Ompia2bdvGiRMnery2efNmLBYLubm55OTkcP78eTZu3EhFRQVWq9Xpe41EhuKP5uZm1fYffvghO3bsoLq6mgMHDvDb3/62R3l7uXPnzvHrX/+a9957jxdeeMGNTyAZCNmRNoLIzs5Gr9eTlJTEjh071OZqdnY2S5cupby8nJKSEmJiYli3bh3Nzc1qxTp37lwMBgOhoaFcv36d+vp6dfEUO/aB+LNmzeLChQuUlpaqEya++c1vevVZ/QF3+UOn06m2d5wYERsbqy6CY8debubMmQQHB7N48WKqqqq899ASGemOJKKjo6moqKCuro7U1FTOnDkDwLhx4ygqKkIIgU6nY8aMGUD3SlT2jhnH5rDBYCAsLIzz58+Tn5+vnrd32oSEhNDQ0MBdd91FdHS0utCKpCfu8gf83fZvvvmmOjGisrKS0aNH9+mjzs5OAgICei0LKfE8Mqc7AnBnDvHgwYMsWbIEnU7n1PusVitWq5XFixeP+LyhFvzhiOMiOyPdN95AVrojAK113Iz0L7bW/OHISPeNN5A53RFAYGBgvaIomtkeIDAwsN7XGnyJ1vzhyEj3jTeQOd0RwPXr1yOFEEpfB/A0cAV4o78ygz2AfwRqgIhblRupu80qirJQUZQkm81WBnwAfN1Vm7vjAOKAEuCEzWb7lqIoy3xpp+GOrHQl3wVCgQuuXkgIkQ+8DexSFGWsq9cbTiiKEgG8Q3flZgTuFEJ87FtV3QghqoBlwJtAMXBIUZTbfatq+CJzuiMcRVHuAi4LIc656XpjgRPAbcCTQoiT7riuv6Moyp+Bx4A6IEUIoblmvKIogUA5EAMUCyHu8a2i4YmsdCVuRVGUUcB54HbgN0KIjT6WpAkURQkAxgghbAMW9jH2VooQot3XWoYjsiNN4laEEF2KoswGXgQsPpajGYQQnYBfbIksK1vPIiNdDRIUFFRns9k007sdGBhY72+dX9KGriNt6BlkpatBtDaO0x/Hbkobuo60oWeQ6QWJS/gyGhoukY9kZCEjXQ1ijzD27NlDaGgo4eHhHD58mCeeeELd3vyTTz5hyZIlJCUlsXPnTjZs2NDjGkKIXvPqjUajuo3OXXfdRUdHB2vXriUrK4unn36azMxMTp06xenTp3nmmWcc9fQbYfgyGhqMrlvZcPz48Vy8eJFHHnlkyDYsKyujuLiY9PR09u3bh16v59NPP+WOO+5gxYoVg9KqVW727c22fPrpp/nVr35FRkYGR48e5YMPPuCHP/zhkG2Zl5dHY2Mj3/72tzl58iSNjY18//vfd9TjdzbsCzlOV8M8+OCDZGZmsmDBAqZNm8bUqVPR6/UYDAZ19S6dTkdoaCgANTU15OXlkZ+fT1tbG0ePHqWwsFBdaerChQusWrWKyspKAAoKCli0aBHjxo1j8eLFACxYsKDXTgX+zK1saF9xyxUbxsXF0dzcTGVlJStWrODatWtERUWpi84MJ262ZUREBCkpKQAsW7aMMWPGuGRLm83GPffcw4ULF5g8eTI3btzwxWN6HFnpapi9e/eyZcsWioqKADCbzeTl5REeHs6kSZP45JNPepSPjIwkIiICIUSPrVu6uroAemyjYzKZuHr1KpWVlVy6dAmTycSHH36I2WzGZDLR2trqtudwXF6wtraWlpaWfsvl5ORQUFAAwKFDh9i9ezfnz58f8r1vZcOysjJMJpNqH3DehuXl5YSFhTF16lSOHj3KbbfdxqRJk6iqqhp2W+LcbMtr166pW75v3ryZyZMn91j9zFlbBgYGUlRUxJQpU6irqxu+K6AJIeShsaPbLT154403ep0TQoimpiZx4MCBPl9zF1/pGbRWIYTIzMwUv/vd70RxcbHYtWuX+OlPfypeeeUVUVxcLKqrq4UQQhiNRlFQUCA+/PBDIUT3M964cUO8/vrrQgghXn/9ddHe3i5yc3PdokurNtTq0Z9vhfCNLf3Rhn0dMqerQQbKk5rNZmbNmgV0R44hISGEhIT0We7UqVMYDAbuu+8+Dh06xJUrV7jzzju5cuUKJ06cYNKkSXR0dLBw4UJ13dY+9CCczOlmZWXR3t5OYmIi1dXV6vmYmBj1KCkpobm5mcmTJzN37lwqKio4ffo0ERERfO1rX+PixYs0NjYyf/589Xld1XWzfYZiR4BVq1aRmZlJZmYm4eHhLFy4EKPRSGpqqtrkHqxWreJJGzp+Fnfs2MFTTz1FZ2cnBw4c4LnnnutPj9/ZsC/k6AU/wV6JJSQkYLFY2LlzJwaDgXnz5hETE0NISAjHjx+npaWFyMhIUlJSKC0tJT09ndzcXAAaGhpYvXo1b731FgEBAYSFhfXY5aG/SncoLFq0iMLCQmJjY7n77rv7LLNkyZIe/8fHxxMfH6/+n5yc7DY9dtxhR6PRSHJyMrfddhu33347RqOR733vexw4cICgoCC3a9Ya7v4sOu4ucvr0aR8/neeROV0/w57nSkhIQK/X93its7OTjo4OtQMnNTWVPXv2oNfrMZlMhIeHs3fvXqZMmcKNGzcwm809dnlwJ/Hx8WzYsIGpU6f2+bqze4FlZWVx7Ngx14V9hSt2vHz5Mg0NDXz22WcEBASQlJREeXk5er2exsZGt2nUOu74LCYmJqq7i1y8eBGTycSlS5e8/izeRKYXNEhfzbqKigoKCwtZuXJlvxWZB/UMqhm/fft2EhMT6erqori4mPXr17N161aCg4OJiIggLS2NvLw8IiIimDBhAlFRUZw8eZIVK1awf/9+1qxZQ3x8PBaLhYqKCgDS0tIICAjocxvyoaQXfGVHf2waSxt6Bple8BNubnr3RXZ2NmvXrh30NfPz87FaraSkpKjjJT/66CNGjRrFD37wA6c1JiUl8e677zJ79myioqKoqqpS85sxMTG9hqLZbDYSExMJCwsjOTkZo9FIfHy82tPtSFlZGdXV1T0q3aHgSTtOmDCBsLAwli1bxvjx413SqWUGsqGz9svKyiI2Npbbb7+dP/3pT/zbv/0bmzdv5pFHHmHOnDluUKwtZKSrQbwVPba2tpKTk8P48eN5/PHHycnJUTU8/vjjjnpc6rCy01e06grO6PKGHWfNmkVLSwvf+MY3mDJlyqC1ahVftGLsFfYf//hHYmJiuPfeex31+J0N+0LmdDVOUlISRqORpqamHtFjXFwcc+bMGVT0CPQYJ2ln48aNTJ8+vcd4ydbWVo+NL42JiXFbhess3rDjlClTaGpqwmKxePPRvIIn7Wffofjy5cuYTCasVisTJ07sNQ592ODrMWvy6H1wi/GRN1NdXS2Ki4sHXX4oMIRxukIIsWvXLqfus23bNtHU1CSef/55dSyvEEJ0dHSIV199VeTk5Iiamhr1ukPV1ReetuOttGr18KfPoT8dMqfr59jHvPqa7Oxs9Ho9SUlJ7NixQ41os7OzWbp0KeXl5ZSUlBATE8O6detobm7mxIkTAMydOxeDwUBoaCg6nU6dnmunvr6ehIQEamtrmTZtmkf0a8WO/oq03+CR6QWJW4iOjqaiooK6ujpSU1M5c+YMAOPGjaOoqAghBDqdTh0LLIRQm5ndQczfsTc38/PzAZg4cSJnz5717gNJJJ7C16G2PHof9NOsG2pz/cc//rEoLy/v8Zq9Cf/GG2+I119/XZw7d04t59iEF92ChLNah8KBAwdEU1PTLcvU1NSI9957zyVdrqY9zpw5I1588cUeZRzPvf/+++I3v/nNoFMhWj28YcO2tjbx9ttvi8zMzB7l8/PzxWuvveb3NuzrkOkFjeLO5rp9xo/jMB97E95xRprjzKDBEhgYWK8ois/W0x2ojCfSHrNnz+41c8rxXE1NDWFhYR5LhXgbT9pw7NixLFy4kCNHjvS4Z2xsLGazedjY0BGZXtAo7mquX7t2TZ3xY2+uw9+b8I4z0uzlnOH69euRQgjFF8dgFjD3RNrDcebUwYMHAdRzFy9eVGf7DRc8acP6+no2bdpEbGys+vns6OigsrKS0aOHZ0wox+lqEHctDH7w4EGWLFmCTqdz6n1WqxWr1aquseuP4yPdubi6O+wobTgybdgXw/OnxM/xZZO9LwbTjNca0oauI23oGWSk62coivLfwBJgkxDiTy5cZxTwP8AHQohN7tLnDyiKMhooAo4IIf7NxWu9DnwT+LUQ4nfu0OcvKIryRyAYeMyVkFhRlJ8B/y+wXwix3l36tIrM6fofK4AwwKVmlhCiC3gceFxRlH9whzA/4hdAO/CiG67VBdwOrHbDtfwGRVFWA0uBdW7IQXQCk4B/dFWXPyDTC/7HTuAPQgiXe2qEEF8oivIYsFdRlGpgkduSeBpEUZQYIAuIB1KFEC5vYiaE+L6iKPvorniHPYqijAVKgFggTQjR995LTiCEeFlRlKPAd1y9lj8g0wsjHEVRUoB3AAMQLYSw+laR51AU5YfAb4HPgFghxPDc+dCDKIoyD/gbcBmYL4Sw+FaR/yHTCyMcIUQZsAqw0N3EG84Y6K4w7pEV7pCZDFQCD8gKd2jISNcNBAUF1dlsNk1UWIGBgfWDGb8qGRpa8LW/+lgLtnPEV3aUla4bcOd4RlcZLmMZtYoWfO2vPtaC7RzxlR1lR9oIw5fRxkCRhRYiIX+NIh3Rso8lMtJ1C/Zf8D179hAaGkp4eDiHDx/m6aef5le/+hUZGRl8+eWXPPfcc7z88svs3LmTDRs29LiGEELd6M+O0WhUt9G56667yMvLo7GxkQULFvDOO+/w3e9+lylTprB27Vr+/Oc/27Xc8tfbl9GGlrU5aBiUxpt9/cQTT1BaWoqiKFgsFm7cuMG//Mu/DNnXx48f5/333+fRRx+ltLSU69evs3r1aqc0+oLB7uZxq+9KdnY24eHhLF261OXvyqpVqzh58iT19fWkpKRQXFxMeno6kyZN8lmkKzvS3MiDDz5IZmYmCxYsYNq0aURERKh7hB05coQFCxag0+kIDQ0FuhdGycvLIz8/n7a2No4ePUphYaE6b//ChQusWrWKyspKoHs1/nvuuYempiYMBgNffPEFBQUFLFq0yBePO6K52ddTp05Fr9djMBi4ceMGra2thISEDNnXixYtIiAggMmTJzNr1ixCQkJ89age4VbflbKyMoQQjB8/3uXvislkoq2tDYC4uDiam5sZO3as15/XEVnpupG9e/eyZcsWioqKgO7FZkwmExUVFbS0tHDmzBmuXr2qlo+MjCQiIgIhRI9tTLq6ugB6bKNjMpkIDAykqKiIxMREQkNDMZvNXL16lcrKSrdtW+24UEttbS0tLX0PwzSbzeTk5FBQUADAoUOH2L17N+fPn3eLDq1rvNnXZrOZvLw8wsPDGTVqFDqdziVfZ2RkEBwcTG1tLRkZGW7fddfXNrzVdyU+Pp5PP/2Ua9euqeWH+l0ZNaq7irNarZSXlxMWFkZzc7NL2l1FphfcQF/NudzcXNLT03uVbW5upqSkhAceeMBTWpxuemZlZdHe3k5CQgIWi4Xy8nIMBgPz5s1TdwQ4fvw4LS0tREZGkpKSQm5uLo8++ii5ubnqpparV6/mrbfeUpvB7tDmDxq97euh2tEbNhzKJqZa/a54CtmR5iEcP0Rms5lZs2YBcPXqVe6+++4+32M2mzl16hQGg4H77ruPQ4cOceXKFe68804qKiqwWq2EhYXR0dHBwoUL1aX03IU9T5aQkNDrtc7OTjo6Oujs7J7ElZqayp49e9Dr9ZhMJsLDw9m7dy/z5893qyZ/0Gj3taOfa2trCQkJ6bPCuNnP586dw2g0kpqaysWLF7FaraSlpZGfn8+CBQucWt94MGjNhu7+ruTk5PDkk09y/PhxFEUhMTFRTV1oAVnpeoibo4qdO3f2iCpCQkJ6RRWlpaWkp6eTm5sLQENDgxpVJCcnYzabufPOO9VFx91V6S5atIjCwkJiY2P7/ZAvWbKkx//x8fE9FkVPTk52ixZ/0+gOP8fGxnLgwAGCgoLUxbtnzpxJcHCwurymOxjONnT8rtgXSh8zZgxVVVUeDwScReZ0PYxjVKHX63u8NtioIjU1VV3U2XHRcXcRHx/Phg0b+s0bZmdnO3W9rKwsjh075rowB26lcaj6ampqeP75592izxU/l5eXo9fruXTpkurnzs5OAgICevXSu4K7/Zyfn89rr73mBmXduOu7Yl8o3WazMXPmTD7//HO3aXQHMqfrBvrKVVVUVFBYWMjKlSvd3gkygJZB5fu2b99OYmIiXV1dFBcXs379erZu3UpwcDARERGkpaWRl5dHREQEEyZMICoqipMnT7JixQr279/PmjVriI+Px2KxUFFRAUBaWhoBAQFYLBYsFou6rYuz2gCv6cvOzmbt2rVD0gi+8bNW7Nja2kpOTg7r1693vLfTOV2tflc8hUwveIibm2VaIykpiXfffZfZs2cTFRVFVVWVmveKiYkhODi4R3mbzUZiYiJhYWEkJydjNBqJj49Xe5IdKSsro7q6ulelqzV9d9xxByaTCavVOuS9uEaynzdu3Mi3v/1tlzVq3YZuR2hgd0x/PxjCjrjO7qaamZkpiouLxb59+8Tbb78t3nvvPfHyyy+L3//+9z3KMcCOqYPVWl1dLYqLi53SOBDu0uYpfe7WaGeovhZCiJ/+9KeiurraYxrdbcdbaRuK7YQYuv0sFov4+c9/LoQQ4ujRo+Lll18etFZPHjLSdSPONuWKiooG3ZRbvnw5FouFmTNnUlNTwwcffEBCQgKFhYUeeRb7ECKt4mt93vC12WxmypQpHn0OX9nRG/aLjo4mLi4OgBkzZmA0Gr3+nH0hO9LcSFJSEkajkaamph5Nubi4OObMmTOophzQY/C3HXvngE6no6GhgUWLFhEUFMTs2bO9+oySbrzha4vFQltbG1br8Fvi2Bv2u3z5spo+Onv2LGPGjPHqM/aLL8Lr4Xbgwyb7zTDEpqezTbht27aJpqYm8fzzz/do/nZ0dIhXX31V5OTkiJqamh7XHaq2oer78ssvVS2O2DWfOXNGvPjii0IIIX75y1+6rNERT/paC3Zsa2sTb7/9tsjMzOzh51tpG6zthNDGd8VTh0wveBFfN4ntZGdno9frSUpKYseOHWqHV3Z2NkuXLqW8vJySkhJiYmJYt24dzc3NnDhxAoC5c+diMBgIDQ1Fp9OpYyLt1NfXk5CQQG1t7ZA7p9ylr7W1VdXiiF3z7NmzOX36NMCQtfaHFnztSTuOHTuWhQsXcuTIEbfbDrRhP08h0wsexNlxjxkZGTQ3N3Pq1Cm2bdvW47XNmzdjsVjIzc0lJyeH8+fPs3HjRnWmmjP3io6OpqKigrq6OlJTUzlz5gwA48aNo6ioCCEEOp1OnXwhhFCbcN0Bwt+xN+Xy8/MBmDhxImfPnnXquT2lz1GLXZ+j5osXL2IymdyybsVQfW336yeffMJLL73Uo8y5c+fYuXMnZWVlvPDCC05r8qQd29vb2bRpE7GxsU7r6gt32a+9vZ19+/aRlZXVo7y9nLPfFU8gI1034c7osaamhrCwsB7Xt0dns2bNUmekRUVFcenSJaeniS5btoxly5YBsGDBgj7L3H///erfEyZM6DWdVa/X09zc3GvZvdGjR/OjH/0I6F5kxN6R4Qt9165dU7U44qjZ/uPmzMpTnmgpOEbddhxnqg0lmvSkHceOHcvOnTsB5/3sSfs5RuCO2Mt5Iip3FlnpuoCiKOOAH0J3VFFaWorBYFCjivDwcDWqmDx5cp9Rhf1vO3V1ddy4cQOz2Ux+fj4PPfQQ0B2dNTY2Mnv2bBoaGrj//vv54IMPKC8v71XpKooyTgjR1pfmwMDAekVRfLbA9UCv+0obwGOPPTagRnCfr+Hvfg0ICFCj7lOnTvHAAw+oM9UaGxudeg4t+xg8a7/6+no2bdrEU0891ef3RxMpC18kkv39oDst8z2gGjjIEMcf3syBAwdEU1OT0++rqakR7733nhDd4gTdm0w+DgQ481zyGJTvnfBM/zjr6zfeeEP9Gx91ALl6uMt2Qrjvu9KfVk8echqwEyjdk8PvA14ErgHPCiFKtLDNjJ3AwMB6m822EvhPQAf8DDgkpKPdghZ87a9b4mjBdo7IjSk1jqIod9JdkRmATcB+LVdkX/1APAj8B9BI9w/ECd+qGr4oirIK+HcgVQgx5FWyFUVZT3fK6k4hxHV36fMHFEWZBxTQ/exVLlxnGfAGMFcIoa3VbpCV7oAoipJA95dpHvB/gBwhRMct36QhFEUJAP4Z+CXwIbBJCOHa8AJJDxRFiQNOAv8ghPjAxWspwJvAFSHED92hzx9QFGUC8AHwnBDi/7rher8AlgIrhBCdrl7PnchKtx8URZlKdyX7EPAy8Ft/jjwURQkEngaepTsPnQ+0CSEKfCrMz1EUJQO4G8gSQrhlncOvKqBSoBDIHe4tFEVRNgL3ABYhxL+66ZoBwDvARaBACPGmO67rDuQ4XQcURZmrKMpjiqK8DJiAS8BMIcSv/bnCBRBC2IQQW4EZQB3wZ+AviqJ83bfK/BdFUW4DfgTogb+567pCiCbgNLCO7g7R4c5PgUWA2xZH+Cq6NQKr6faRZpBDxr5CURQDcAQYB+QCSUKI2lu/y/8QQjQpivIa3U2vWLo/lB/5VJT/cjtwA9hB94+0O/lPIJHutNaw5at0ig7IoTuf6052AguAFDdf1yV8nl7wdY+mvQdTUZR/BjLoHm71L67m5vwRX/viZvy1l14iuRU+r3RvtQOsl+6P8MHq8VrE1764GekbyXBEphckwx5fRfCDidS10LrQus5b6dOC/RwZjC010ZG2Z88eCgoKOHXqFC+88AINDQ3q/PicnBwsFkuP8l1dXX1e5w9/+AN//OMfAWhra+Mvf/kLu3btoqOjg+9973tYLBZefvnlYbk+qTu5lT9OnDjBv//7v9PU1ERGRkav9/YVKRuNRt588011/nxeXh47duzg888/5+DBg2zZskX1kSew2WyTfDHzaDCVga+0+ZPOW+nTgv2ctaUmKt0HH3yQzMxMFixYwLRp04iIiFD3cXJcoCI/P5/8/Hw+/vhjLBYLhYWFFBYWqjuE3nbbbQQGBgLdKylNnjyZGzduUFBQoC76bTAY+OKLL7z+jP7ErfwxY8YMrl27RnBwMKGhoQDU1NSQl5dHfn4+bW1tHD16lMLCQsxmMwAXLlxg1apVVFZWAt0LUt9zzz1YLBamT5/OihUrVB9JJMMdTVS6e/fuZcuWLRQVFQFw7do1TCaTug2HndmzZ6MoCl1dXX2uGN/a2sr169eprKykqamJuro6FEXh6tWrVFZWMmrUKEJDQ9XKQNI3t/JHeXk5wcHB2Gw2tXxkZCQREREIIXr4xd4iiYmJIS8vj+nTp2MymQgMDKSoqIj4+Hjee+89vvnNb6o+cscyi87i+Hmora2lpaWl33I5OTkUFHR3sh86dIjdu3dz/vz5Ea9R6/q0pFFzHWm5ubmkp6er/7/zzjukpqai1+s9dX/ZWfMVfXWk3ewPO83NzZSUlPRaCtDNetzim76eKysri/b2dhISErBYLJSXl2MwGJg3b566gPbx48dpaWkhMjKSlJQUcnNzefTRR8nNzeXxxx8nJyeH1atX89Zbb7F69eoh6b9V56U3NLqiUwv6Bur89ZZGZ2ypuY40+xfcbDYza9Ys7r33XvVXKSQkpFd5s9nMqVOnMBgM3HfffZw7dw6j0Uhqaiqffvopx44dY+bMmUyZMoX777+fUaM0Edz7DTdXuHa/6HQ6UlNTB+2XQ4cOceXKFebPn8/Zs2e5cuUKd955JwcOHOC5557z1uP0onuYKCQkJPR6rbOzk46ODjV9lZqayp49e9Dr9ZhMJsLDw9m7dy/z588f0Rq1rk9rGjUV6brjV6mzs5OMjAweeOABJk6cyDvvvENISAitra1861vf6lVByEj37/QXNbg7Wli2bBlHjhzhn//5n8nOzmbt2rX96fFYpFtRUUFhYSErV65k6tSprt6iv/u6FOl6Q+NXGoakUwv6Bop0vaXRQY//Rbrg2q9SQECAuvDz6dOnefjhhzGbzRw/fpzLly/3GZVJBoe7ogX7ItOO2+UYDAavPkt8fDzx8fFevaezaF2j1vWBRjX6eogFDgsbl5eXi23btomLFy8Kb4GfLgjtiYN+Fpn2hV+EcJ9v+nuuW+HsrrlHjx4VL7/8stP6h6JtKPoyMzNFcXGxsFgs4uc//7nmdQ5Wny/tt3//frF9+/ZBa7Ufmop0NfmrJBk2ftm+fTuJiYl0dXVRXFzM+vXr2bp1K8HBwURERJCWlkZeXh4RERFMmDCBoqIiTp48yYoVK9i/fz9r1qwhPj4ei8WijqxJS0sjICCAGTNmYDS6tl6LJ/UtX74ci8VCdHT0kPat87ZOrepytN/y5cvJyclxWqff9io5u6PnSy+9xKuvvuoZMSMcZ32RlZXFsWPH+Mtf/sK+ffswGo3qOU+SlJSE0WikqamJqKgoqqqqSElJIS4ujjlz5hAcHNyjvM1mIzExkbCwMJKTk9VKta/himfPnmXMmDGa1WffAfny5cuYTCaXJgh5Q6dWdTnab+PGjUyfPt1pnZrqSHP2lyoqKmrQv1QvvPACQUFB/OQnP7n5/gjZkQZ4zxcWiwWLxcLEiROpqanh/PnzPPTQQ1gsFnVn2K/0uMU3g11Twq7LUYOL9x1QvzPrXbhbn4MGTet0pSPNk7r60TOgLTUV6Xryl2r06NFqR5BkYLwRNeh0OhoaGli0aJFLEY67iImJ8egX0lW0rs+OVnVqRtdASV9PHziRCK+uru6VZHcVZEeaZnxxM+7yTX/P5WxnyrZt28SXX34pXn31VZGTk9Pjtfz8fPHaa6+Jmpoa9bqD0e9ObU1NTeL5558X1dXV4syZM+LFF1/sUebgwYMiJydHnDt3Tvzyl79Uz3tbZ382tGt3tOFA+jxtv7a2NvH222+LzMxMtWxHR4eq3xmt9kNTHWkDYR8TKvE9/uaL7Oxs9Ho9SUlJ7NixQ414srOzWbp0KeXl5ZSUlBATE8O6detobm5WF+iZO3cuBoOB0NBQWltbSUhIoLa25/r2sbGxmM3mHmuFeFubTqdj+fLlQPeU+dOnT/e4T0NDgzpW2pc6+7OhXbuz2jxpv7Fjx7Jw4UKOHDmi3q++vl7VPxQ7aiq9cDPOdtBkZGTQ3NzMvn37yMrKUs8LIdi2bRsnTpzAarU6fV2J+3wBsHnzZiwWC2+88Qa5ubm89957bNu2jddff91j/omOjqaiooK6ujpSU1M5c+YM0L0wUlFREUIIdDodM2bMALo/M/a0yFcRFQATJ07k7NnufT3z8/MB6OjooLKyktGjhxbDuEsb/D114zgG+uDBgwDqWOnU1FSf6uzLho7afaXLUYPdfvX19WzatInY2FhVq6P+ITFQKOzpg6+aB7t27RIHDhwQFotF/OxnPxOHDx8Wu3btErt27RLV1dXif/7nf8Rzzz0n/vCHPwghhGhqahIFBQWioKBAfPHFFz2aFJ9//nmPpsvnn38unn32WfHXv/61R7nBNgdGyuENXwghRHFxsaiurhZvvvmm+I//+A9RUVEh9u3bJ3784x/3eK+7fMMQx3LezIEDB0RTU9Mty9TU1Ij33ntv0Pq9qc2RN954Q/1bazodbTiQPl/Zbyha7Ydm0gvR0dGUlpZiMBjUX6vw8HD112ry5Ml9/lrZ/7bT3t6uznjKz8/noYcewmAwEBYWxvnz51m2bJlPns+f8KQvoDuaaGxsxGazMXPmTL744gsCAgJISkryyPMEBgbWK4rik0XMB1PGF9oAHnvsMVXDQGV9qfNW+nypqy8GY0tNDRlzlYMHD7JkyRJ0Ol2/ZaxWK1arlcWLF9vvj5BDxgDv+6IvHP0jfSMZjvg80vX1L9VgfplGCoGBgZe+2hVZE0jfSIYjPu9Iu379eqQQQnE8vtL1NvDaza85cwBfA+qAZf2VkbvNdm+DrSjKkzabTQF+Doxxxe6uHsAc4CObzfa/iqJM8a11JBL34vP0Ql8oivIM8H3gLiFEm4vX+gcgC0gVQsh9ehxQFCUC2Ae0AhOBtUKIj32rqhtFUcbS/QOwHtgPmIQQr/lWlUTiOpqqdBVFuR24H/gF3RVupZuu+x/APOAtIcQf3XHN4YCiKAXAvcBh4B+FEDd8LKkXiqKsBDKBYGCWEKLKx5IkEpfweXrhJh4HXgEOu6vC/YocYBbwe0VRbnPjdf2dZmAX8HstVrhfcQL4T+B9QDP5ZolkqGgt0v0AiAN+IITY68brhgK/B74L3C2EKHHXtSUSicQZtFbpTgSaXM3j3uL6UcCnbhsX5SRBQUF1NptNU2MK/a0jUUs29Ef7SXyPpird4Y47x8G6A38cB6slG/qj/SS+R2s5XYlEIhnWOD05wpfNu8E257Succ+ePYSGhhIeHs7hw4d54oknKC0tRVEUxo8fz8WLF3nkkUfYuXMnGzZs6PFeIUSvdYGNRiOfffYZUVFR3HXXXWRkZHDHHXcQFxdHXl4e3/3ud7ly5QrFxcWkp6czaZImWucucSsb6vV6iouLeeaZZ9i1a9eQbJiXl0djYyPf+MY3+N///V/CwsJ4+OGHWbt2LX/+85+9+KSS4YbTka7NZps00IIOnjoGW5FqXeODDz5IZmYmCxYsYNq0aUydOhW9Xo/BYFCXltPpdISGhgJQU1NDXl4e+fn5tLW1cfToUQoLCzGbzQBcuHCBVatWUVnZPeAjKiqKxsZGgoKCMBgMfPHFF8TFxdHc3MzYsWOddbkmuZUNZ8yYwbVr1wgODh6yDW02G/fccw+tra1MmjSJjz76iIKCAhYtWuSrR5YMEzySXrB/kAFqa2tpaWnpt1xOTg4FBQUAHDp0iN27d3P+/HlPyNKMvr1797JlyxaKiorU++Tl5REeHk5ZWRkmk4muri61fGRkJBEREQgheuzEYC8TExNDXl4e06dPx2QyMWnSJKqqqmhvbyc0NBSz2Ux5eTlhYWE0Nze7pF0r3MqG5eXlBAcHY7PZ1PLO2jAwMJCioiJmzpxJZ2cnycnJXL16lcrKSi5duuSTZ5YMD5zuSOuvIyMrK4v29nYSEhKwWCyUl5djMBiYN2+euuD18ePHaWlpITIykpSUFHJzc3n00UfJzc3l8ccfJycnR11kefXq1X3de1AdF31p9Ia+gTT2pSs3N5f09PReZZubmykpKeGBBx4Y6HGHjD92BGnJhv5oP4nvcXuka8+VJSQkoNfre7zW2dlJR0cHnZ2dAKSmprJnzx70ej0mk8nlRZb9UZ9jZeEYgV+9epW77767z/fcKgK3LxD+ySef8NJLL7lNp5a5ucK121Gn05GamjrolgzAqlWrADh16hTbtm3rcU4icQduW2Vs0aJFFBYWEhsb229lsWTJkh7/x8fHEx8fr/6fnJzsLjl+o+/mCHznzp09IvCQkJBeEXhpaSnp6enk5uYCPbdhudV2LcMZd9jRaDSqPq6pqSEsLKzHOYnEHbit0r25gtIaWtfnGIHfzGAj8Pnz51NQUEBjYyMBAQHqdi0Gw8iZPeuKHS9fvkxDQwNWq5UbN25gNpsJDQ1Vzw1lPyyJ5GbcltMdiOzsbNauXTvo8r/73e+YOXMmK1ascLz3kHO67taXn5+P1WrlmWeeufneTuV0KyoqKCwsZOXKlUydOtUpza7ijznJ/nzrCzv6o/0kvselSHf79u0kJibS1dVFcXEx69evZ+vWrQQHBxMREUFaWhp5eXlEREQwYcIEioqKOHnyJCtWrGD//v2sWbOG+Ph4LBYLFRUVAKSlpalR2u233+7Sw3lS3/Lly8nJyXFJH2g/AvcXpB0l/oJLHWlJSUkYjUaampqIioqiqqqKlJQU4uLimDNnDsHBwT3K22w2EhMTCQsLIzk5GaPRCNBjCI+dWbNmce7cOVfkeVTfxo0bmT59ukv6Bouzu+NmZWVx7NgxDh06xNtvv83hw4d56aWXePXVVz0j0I9w1pZFRUW88sornhEjGZF4NL1gsViwWCzqPvSu4u70grv1fXXvQaUXnI3Co6KiBh2F259LURTef/99Fi1axF//+leCgoL4yU9+MiitWqUv33rSllarlV27dvGLX/yiLy1+Zz+J7/HoHmn28a9axZf6kpKSePfdd5k9e3aPKNyuazBReHx8vBqFO1JWVkZ1dTXTpk1j9uzZNDQ0MHr06F5TX4cLnrTl2bNnGTNmjLceRTIScHaaK7fYZ37Xrl39vtYX27ZtE19++aV49dVXRU5Ojnq+q6tL/OY3vxHHjx8XNTU16nUZxJ7yt9I4FH1NTU3i7bffFpmZmer5jo4OVbOjvoE03sp2N1NdXS2Ki4ud0ussg7Wnlg5nbGjHU7b0R/vJw/fHkCPd7Oxs9Ho9SUlJ7NixQ22iZ2dns3TpUsrLyykpKSEmJoZ169bR3NzMiRMnAJg7dy4Gg4HQ0FBaW1tJSEigtrZWvXZ9fT319fW0tbUNeZiOu/TpdDoWLlzIkSNHeuiza/bUMCKttxL8CWlLiZYYckdadHQ0FRUV1NXVkZqaypkzZwAYN24cRUVFCCHQ6XTMmDED6I6o7Z1RQvw9Jzdx4kTOnj0LdA/DAjAYDISFhbm0xoG79LW3t7Np0yZiY2NVfY6a3YGznTsZGRk0Nzers88csZ974403yM3NpaysjIMHD7Jx40asVqvT9/JH3GXP9vZ29u3bR1ZW1oixncTzDDnSXbZsGcuWLQNgwYIFfZa5//771b8nTJjQaw68Xq/n2rVr/OhHP+pxPiAggGeffRYAq9VKXFycz/TZbDZ27tzZ4/zo0aNVzc7qc2cEbp995oj93JgxY6iqqmL+/PksWrSI1tbWYTm435P2HDt2rNrKGY62k/gGpyvdwMDAekVRfLZW7WDLaVVjdHQ0paWlGAwGNQIPDw9XI/DJkyf3GYHb/3akrKyMxsZGPvroIx566KEe52w2GzNnzuTzzz/n/fff5+GHH/bE4/ocT9rT3sp56qmnvP5ckuGL3K7Hi7hrq5mDBw+yZMkSdDqdU++zWq1YrVYWL15s14PwsyFPntiuZzD2vNl2X2nxO/tJfI9Hh4xJeuLLCLwvBtty0BJasqE/2k/ie2SkqxGU7kG0/xeoF0I87cJ1vgVkArnAZuGhnZW1iqIoLwCLgHuFEJ1DvEYCUAIsF0J85E59EoncmFI7/CswHfixi9f5G9AI/H9Akqui/AlFUVYATwKPDbXCBRBClNPthzxFUYIHKi+ROIOsdH2MoihTFUW5H/gF8KgQwjbQewagEdgBCOAeV/X5A4qi6BRFWQbkAI8LIepcvaYQIgc4AfxOURS5MZrEbcj0go9RFOW3wGPAfwkhek/wH/p13d/jpFEURfkB8O/AUSFE3/soDe26U+mueCcDE4QQ19x1bcnIRUa6vuch4Dbgc3dedKRUuF+xGogAPnXzdQVwhe4O58UDlJVIBoWMdH2MoiiPACfc0SQeqSiKcjdwRQjxsQeurdBdqR8SQjS5+/qSkYesdP2coKCgOpvN5vMhVIGBgfXXr1+P9LUOiUTryErXz9FK6lZOFJBIBoecHNEPWokg7fh7JOlLew7Wdv6gUeL/yEi3H7QSQdrpL5JUFEXk5uYSGhpKeHg4hw8f5oknnqC0tBRFURg/fjwXL17kkUceYefOnWzYsKHH+4UQvRY3NxqNfPbZZ0RFRXHXXXeRkZHBHXfcwR133MGePXswGAzMmDGD06dPqxtzDhTp+tKentzQ1F3IlsLIQY5ecBNms1n9u7a2lpaWln7L5eTkUFBQAMChQ4fYvXu3S8tYPvjgg2RmZrJgwQKmTZvG1KlT0ev1GAwGdeUsnU5HaGgoADU1NeTl5ZGfn09bWxtHjx6lsLBQfYYLFy6watUqKisrAYiKiqKxsZExY8bQ0NBAV1cXCxYs6LUjg6v40obDQZ/EP5DpBRfIysqivb2dhIQELBYLO3fuxGAwMG/ePGJiYggJCeH48eO0tLQQGRlJSkoKpaWlpKenk5ubC0BDQwOrV6/mrbfeUlfCcpa9e/eyZcsWioqKgO4vfV5eHv/6r/9KWVkZJpOJrq4utXxkZCQRERFcvXq1x6ab9jIxMTHk5eUxffp0TCYTkyZNwmg0MnPmTL72ta9x48YNzGYzJpOJ1tZWxo8f7/c29Fd9Ev9DVrpuwN48T0hI6PVaZ2cnHR0ddHZ2z0pNTU1lz5496PV6TCYT4eHh7N27l/nz5w/5/o5LD+bm5jJr1iz+67/+Sz2XkpJCc3Mzer0e6F7I3XHt2G9961s9rrdkyZJe97CvrpWcnKye27Zt25A134yvbejv+iT+g8zp9sNg8nsVFRUUFhaycuVKpk6d6mk9/eZ0b6XTbDYza9YsoLtJHBISQkhISJ/lTp06hcFg4L777uOTTz7hwIEDPPfcc2zevJknn3yS1tZW9dxg9Q2k0xs2dCWn6y0fy5zuyEFGui4QHx9PfHy8r2X0wh1N4tmzZ3P69Gng77tROJ5zF1q1oR2t65P4H7Ijzc04u49WVlYWx44d49NPPyUnJ4fdu3er51zFsUlsTy3YGahJfPHiRUwmE5cuXaKsrIwPP/ywxzlvMVR7egtn9eXn5/Paa695RozEL5DphX5wbGpu376dxMREurq6KC4uZv369WzdupXg4GAiIiJIS0sjLy+PiIgIJkyYQFRUFCdPnmTFihXs37+fNWvWEB8fj8VioaKiAoC0tDQCAgKwWCxYLBaWLl1KTk4O//RP/8SlS5fUcw56Bp1e8GbaYyB9Dq973Z6D1XazRk/qa21tJScnh/Xr1ztlP8nwQUa6gyApKQmj0UhTUxNRUVFUVVWRkpJCXFwcc+bM6TV0ymazkZiYSFhYGMnJyRiNRoAeIwXs2KNIgGvXrjF+/Pge54ZCfHw8GzZsuGWF646IfKh4y55a1Ldx40amT5/ukj6JfyMj3X5wZqB8X9GVB/QMGOl6OyJ3HCrmzskR7ranuydHeMLfMtIdOciONDcQExNDTEyMr2WQlJTEu+++y+zZs3tEaNCtcTARWnx8vBqhOVJWVkZ1dTVLly5VI3JPoRV79ofW9Uk0jhBCHn0c3abpm127dvX7Wl9s27ZNfPnll+LVV18VOTk5PV57/vnnRXV1tTCbzeKVV14RJSUl6rmamhr1Xl/pcUrnzVRXV4vi4mKntA+W/vQJD9mzqalJtZOdjo4O1caDsd1gNbrL321tbeLtt98WmZmZPfQ5o1Ee/n/ISHcAsrOz0ev1JCUlsWPHDrVJmZ2dzdKlSykvL6ekpISYmBjWrVtHc3MzJ06cAGDu3LkYDAZCQ0NpbW0lISGB2traHte3D8eaOXMmwcHBLF68WB1RMG3aNLc+ixYiNHfZU6fT9ZjgAVBfX6/aeKi286S/x44dy8KFCzly5IjbfSvxH2RH2gBER0dTUVFBXV0dqampnDlzBuie1VVUVIQQAp1Op07vFEKonSfdAUw3EydO5OzZs0D3sCE79o6fzs5OAgICUBTFLZ1B4HxnWUZGBs3NzWzevBmLxdLjNfu5d955h7y8PK5cucILL7zgtCZ32RP+bju7PR1tPFQ86e/29nY2bdpEbGysSxol/o3sSOsHd644dfDgQZYsWYJOp3PqfVarFavVyuLFiwfsSOsrQrNHWYON0LKzs1m7di3Hjh3rFRXbz/35z39mzpw5pKSkcOTIEdauXWvX0ae+m3W6g8HYczC285RGZ/V9de9BaZT4PzK90A+BgYH1iqJoaj3dW70eHR1NaWkpBoNBjdDCw8PVCG3y5Ml9Rmj2vx0pKyujsbGRjz76iIceeqjHucTERNra2qiurnZav6/sOZDtHMtpXaPE/5GRrp/jy4g8NzeX9PR0uw4ZqUkkg0BWun6OVhZbl5WuRDI4ZHrBz9FKGkQ2jyWSwSFHL/g5169fjxRCKDcfQCRQC9zb1+vOHMD3gXIguL8ycn8viWRwyPTCMEPpXlpsErAbOCWEeN5N130dEMBPhRBfuOOaEslIRFa6wwxFURYCbwCXgbuEEB0DvGWw1x0PmIBgYL4QwuqO60okIw2ZXhh+PALcDtzm5uuOAcbRHUXf5+ZrSyQjBlnpDj9OAM8CX3dXlAsghPgSiAX+EzjjrutKJCMNmV6QSCQSLyIjXYlEIvEicpyuDwgKCqqz2Ww+m2460PAuX+qzMxidEok/ItMLPsCXs8gGM3NMC7Pc5Aw3yXBFphc0itlsVv+ura2lpaWl33I5OTkUFBQAcOjQIXbv3s358+dHtD6JRKvI9IKGyMrKor29nYSEBCwWCzt37sRgMDBv3jxiYmIICQnh+PHjtLS0EBkZSUpKCqWlpaSnp5ObmwtAQ0MDq1ev5q233lJXFBsp+iQSf0BWuhqke1IZJCQk9Hqts7OTjo4OdXeJ1NRU9uzZg16vx2QyER4ezt69e5k/f/6I1SeRaBmZ0/UB/eVMKyoqKCwsZOXKlbfcPt3Few85p+sNfQ4aZE5XMiyRla4PkB1pAyMrXclwRXak+RHO7nmWlZXFsWPHPKLlZoaqrbS0lJycHC5evOgZYRKJxpCRrg9wjCS3b99OYmIiXV1dFBcXs379erZu3UpwcDARERGkpaWRl5dHREQEEyZMICoqipMnT7JixQr279/PmjVriI+Px2KxUFFRAUBaWhoBAQFYLBYsFou6o+1X9x50pOsNbR999BGxsbHExsYSHx/vlE6JxB+Rka6PSUpKwmg00tTURFRUFFVVVaSkpBAXF8ecOXMIDg7uUd5ms5GYmEhYWBjJyckYjUYAurq61F1p7bi6q7A3tCUnJ3Pt2jUqKyuHrFMi8SdkpOsDnMmZ9hWtunhvt+V03a3tJg0y0pUMS2Sl6wNkR9rAyEpXMlyR6QWN4WyHVEZGBs3NzWzevBmLxaKe7+zsZPv27ezevRur1er0dd2lrampSdXhiF3vO++8Q15eHleuXOGFF15wWaNEonXk5Agfkp2djV6vJykpiR07dqjN9OzsbJYuXUp5eTklJSXExMSwbt06mpubOXHiBABz587FYDAQGhqKTqdj+fLlPa5dX19PQkICtbW1TJs2zWfaWltbVR2O2PX+7W9/Y86cOVy/fn1IOiUSf0NGuj4kOjqaiooK6urqSE1N5cyZ7rXBx40bR1FREUIIdDqdOl1WCKF2SN3c/Ld3TOXn5wMwceJEzp4963Ntjjrs2hz1JiYm0tbWRnV19ZC1SiT+hMzp+gB35kwPHjzIkiVL0Ol0/ZaxWq1YrVYWL17s1ZzuYLQ5kpubS3p6ul2DzOlKhiWy0vUBcj3dgZHr6UqGK7LSlUgkEi8ic7oSiUTiRWSlK5FIJF5EVroSiUTiRWSlK5FIJF5EVroSiUTiRWSlK5FIJF5EVroSiUTiRWSlK5FIJF5EVroSiUTiRWSlK5FIJF5EVroSiUTiRf5/O9zXZZ+jm8cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#todo: calculate feature importance\n",
    "# here's a bit of scaffolding for how to look at feature weights using an sklearn SGDClassifier\n",
    "# (reminder that the other part of the lab covers this in more detail)\n",
    "def printWeights(cols, weights):\n",
    " for i in range(len(cols)):\n",
    "    print(f\"{cols[i]} has a weight of {weights[i]} \\n\")\n",
    "\n",
    "print(\"Coefficients and intercept for SKlearn SGDClassifier: \")\n",
    "# create, train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.4, random_state=0)\n",
    "sgd = SGDClassifier(loss='log', max_iter=100,shuffle=False, tol=None, penalty='none', learning_rate='constant', eta0 = 0.1)\n",
    "sgd.fit(X_train,y_train) \n",
    "weights = list(sgd.coef_[0]) + list(sgd.intercept_)\n",
    "printWeights(X_train.columns,  weights)\n",
    "print(\"Coefficients and intercept for linear svm: \")\n",
    "linearSvm = svm.SVC(kernel='linear')\n",
    "linearSvm = linearSvm.fit(X_train, y_train)\n",
    "weights = list(linearSvm.coef_[0]) + list(linearSvm.intercept_)\n",
    "printWeights(X_train.columns,  weights)\n",
    "print(\"weights of tree:\")\n",
    "treeClassifier = tree.DecisionTreeClassifier()\n",
    "treeClassifier = treeClassifier.fit(X_train, y_train)\n",
    "tree.plot_tree(treeClassifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  What features seem to be most important for identifying cancer?  Is it the same for different methods, or is the relative feature importance consistent across different classifiers?\n",
    "\n",
    "All of the features having to do with concavity have the weights with the largest magnitude and thus seemingly would sway the identification the most. Additionally, worst radius, perimeter, texture, and area all have large magnitudes as well. It seems other methods have similarly classified weights, as a linear svm, although far from identical, seems to also place high weight on features having to do with concavity.\n",
    "\n",
    "2.  We can't say a feature close to weight 0 is irrelevant to a task.  Why is that?  As a hint, if we were to start removing other features from the data set, would you expect some of the small weights to stay small or grow bigger? \n",
    "\n",
    "We cant disregard the features with smaller weights because they still play a role and the combination of multiple small features that may be linked could be more significant than an unrelated other variable of higher weight. Also as hinted at, without them , other variables could have their weights bumped up, leading to an underfit algorithm which places higher weights on oher variables.\n",
    "\n",
    "3. How does feature importance play into our overall evaluation of the appropriateness of a classifier for our task?\n",
    "\n",
    "If a model is very dependent on a feature that we know is more error prone or harder to gather, it might not be as appropriate as one that depends on better more sure sources.\n",
    "\n",
    "4. For this task in particular, how might the availability (or absence) of feature importance information impact the real-world usefulness of a model?\n",
    "\n",
    "Knowing which features are more important in this case could be valuable as gathering the info could have some errors, or there could be cases when a doctor would know that a feature might be unusual in a certain patient and having the knowledge of how that might affect the task would be important. Also if efficiency is an issue, possibly simplifying the system coudl be an option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "Todo: Describe what performance measure(s) you will focus on for this dataset (e.g. accuracy, precision, recall, confusion matrix, etc.).  Be sure to include your reasoning showing why and how you came to your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this, we will depend mostly on accuracy. We will assume that we want to prvent false positives most of all, as well assume that this system is being used to detect cases that otherwise might have slipped through and thus we don't want to accidentally pick up cases that are otherwise not double-checkable\n"
     ]
    }
   ],
   "source": [
    "#todo: code to calculate the chosen performance measure(s) \n",
    "print(\"For this, we will depend mostly on accuracy. We will assume that we want to prvent false positives most of all, as well assume that this system is being used to detect cases that otherwise might have slipped through and thus we don't want to accidentally pick up cases that are otherwise not double-checkable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Methodology\n",
    "\n",
    "Todo: Describe what method you chose to evaluate your chosen performance metric(s) (e.g. hold-out validation, k-fold cross-validation, etc.).  Be sure to include your reasoning for why this choice is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: code to robustly evaluate the performance measures for a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Todo: Based on your results, what classifier would you choose to do this problem?  Does this seem like a reasonable choice?  Describe a potential use case for such a system where your classifier would be appropriate.  Describe another potential use case where your classifier would not be adequate for real-world use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: apply above code to several classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5b: Digits data set\n",
    "Put your own analysis for the digits dataset below.  You can use the earlier sections as examples, but be thoughtful about what's relevant and useful here; not all data sets require the same approach, and \"more\" is not always \"better\".  However, this section should be substantial enough overall to demonstrate careful work and thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
